# 英語を話せる森川さん
1つめの実験は初めてというのもあっていくつか微妙な点が多かった。
ちゃんと改善させたい。

ポイントは以下
- Libri-TTSは全部を使わない。
  - train-clean-100 のみにしてみる
- 藤崎さんデータも混ぜる
- モデルのセーブ間隔を短くする
- phoneme embeddingは保存済みから削除してみる。
  - exps/20220425_pro_eng_2/pretrained_model_from_opensource_del_text_emb.pth 
  - ここに text_encoder.emb.weight だけ消した重みを保存した

## まだある問題点
- 結局、音素数で分割すると、
  - max に関しては、400が限界。これ以上増やすとbatch sizeを16にしてもだめだった
    - これは嘘。単にGPUのメモリ開放ができていなかっただけ。
    - ただ、正直400→800にしてもデータ数自体は1000くらいしか救えなかったので正直どうでも良さそう
  - min に関しては、70が限界。これ以下はsegment error
    - ただ、このsegmentをいじってしまうと重みとずれてきそう
    - なのでこれ以上は減らせないか?
  - そして、上２つを守ると 25000ほどデータが削れてしまい。ほぼ半分。これはやばい。
  - とりあえず、森川さんが削れていなければ良いと思うので、調べてみる。
    - min: 37
    - max: 181
    - mean: 100
    - 70以下の数: 112個
  - 695個中112個ならまぁ許容範囲。これでヨシ

  - 1000epoch回しても微妙なので，藤崎さんデータに関しても調べてみた
    - min: 9
    - max: 445
    - mean: 62
    - 70以下の数: 17517
    - 400以上の数: 3
    - 全体: 24887
  - うーん削れすぎ．せめて言語ごとに閾値を変えるべきかもしれん．これをやってみる？
    - 60以下の数: 16656
    - 50以下の数: 15516
    - 40以下の数: 12820
    - 30以下の数: 6707
    - 25以下の数: 2979
    - 20以下の数: 1610
    - 15以下の数: 222
    - 10以下の数: 4
    - せめて十分の1くらいの25以下にしたい．
